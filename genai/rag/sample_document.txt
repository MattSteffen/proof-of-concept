Retrieval-Augmented Generation (RAG) combines information retrieval with large language model generation.

In a simple RAG pipeline, a query is converted to an embedding vector and compared against pre-embedded document chunks to find relevant context.

The selected context is inserted into a prompt before sending the prompt to the language model, which makes answers more grounded in source material.
