# sample_data.txt (create this file)
sample_texts = [
    "The quick brown fox jumps over the lazy dog. This pangram contains every letter of the alphabet.",
    "Machine learning is a subset of artificial intelligence that enables systems to learn from data.",
    "Python is a high-level programming language known for its readability and versatility.",
    "The transformer architecture revolutionized natural language processing in 2017.",
    "Neural networks are inspired by the biological structure of the human brain.",
    "Deep learning models can achieve remarkable results on complex tasks like image recognition.",
    "Natural language processing enables computers to understand and generate human language.",
    "Gradient descent is an optimization algorithm used to minimize the loss function.",
    "Attention mechanisms allow models to focus on relevant parts of the input sequence.",
    "Tokenization is the process of converting text into a sequence of tokens or integers.",
]

# For real training, you'll want much more data (megabytes to gigabytes)
# Good sources: Project Gutenberg, Wikipedia dumps, Common Crawl